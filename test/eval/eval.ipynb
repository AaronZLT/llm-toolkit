{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdb/zhanglongteng/anaconda3/envs/llmtoolkit/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-10 12:23:26,279] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[319, 350, 315, 360]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "import threading\n",
    "import time\n",
    "import datetime\n",
    "from os.path import exists, join, isdir\n",
    "from dataclasses import dataclass, field\n",
    "import sys\n",
    "from typing import Optional, Dict, Sequence, Tuple, Union\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from packaging import version\n",
    "from packaging.version import parse\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    set_seed,\n",
    "    Seq2SeqTrainer,\n",
    "    BitsAndBytesConfig,\n",
    "    LlamaTokenizer\n",
    ")\n",
    "from transformers.activations import ACT2FN\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "import evaluate\n",
    "\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    PeftModel\n",
    ")\n",
    "from peft.tuners.lora import LoraLayer\n",
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n",
    "\n",
    "import deepspeed\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "\n",
    "'''\n",
    "param\n",
    "'''\n",
    "\n",
    "# llama2chat = \"/hpc2hdd/home/lzhang330/ssd_workspace/models/llama-2-7b-chat-hf\"\n",
    "# llama2 = \"/hpc2hdd/home/lzhang330/ssd_workspace/models/Llama-2-7b-hf\"\n",
    "llama = \"/mnt/sdb/zhanglongteng/data2/share/llama-1/llama-7b-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    llama,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False, # Fast tokenizer giving issues.\n",
    "    tokenizer_type='llama', # Needed for HF name change\n",
    ")\n",
    "\n",
    "abcd_idx = [\n",
    "    tokenizer(\"A\").input_ids[1],\n",
    "    tokenizer(\"B\").input_ids[1],\n",
    "    tokenizer(\"C\").input_ids[1],\n",
    "    tokenizer(\"D\").input_ids[1],\n",
    "]\n",
    "\n",
    "print(abcd_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_dict2file(dictionary:Dict, filename):\n",
    "    lock = threading.Lock()\n",
    "    lock.acquire()\n",
    "    with open(filename, 'a') as json_file:\n",
    "        try:\n",
    "            json.dump(dictionary, json_file, indent=4)\n",
    "            json_file.write(\"\\n\")\n",
    "        finally:\n",
    "            lock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 319], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lm_eval\n",
    "llama2 = \"/mnt/sdb/zhanglongteng/data2/share/zhanglongteng_A6000/Llama-2-7b-hf\"\n",
    "\n",
    "device:str ='cuda'  # 'cuda' or 'cpu'\n",
    "task_manager = lm_eval.tasks.TaskManager()\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     args.model_name_or_path,\n",
    "#     cache_dir=args.cache_dir,\n",
    "#     load_in_4bit=args.bits == 4,\n",
    "#     load_in_8bit=args.bits == 8,\n",
    "#     device_map=device_map,\n",
    "#     torch_dtype=(torch.float32 if args.fp16 else (torch.bfloat16 if args.bf16 else torch.float32)),\n",
    "#     trust_remote_code=args.trust_remote_code,\n",
    "#     use_auth_token=args.use_auth_token\n",
    "# )\n",
    "\n",
    "# results = lm_eval.simple_evaluate( # call simple_evaluate\n",
    "#     model=lm_obj,\n",
    "#     tasks=[\"taskname1\", \"taskname2\"],\n",
    "#     num_fewshot=0,\n",
    "#     task_manager=task_manager,\n",
    "#     ...\n",
    "# )\n",
    "# lm_eval.tasks.initialize_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08:16:12:54,635 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-04-08:16:12:54,636 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': '/mnt/sdb/zhanglongteng/data2/share/zhanglongteng_A6000/Llama-2-7b-hf', 'tokenizer': '/mnt/sdb/zhanglongteng/data2/share/zhanglongteng_A6000/Llama-2-7b-hf'}\n",
      "2024-04-08:16:12:54,638 INFO     [huggingface.py:163] Using device 'cuda'\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 22.95s/it]\n",
      "/mnt/sdb/zhanglongteng/anaconda3/envs/llmtoolkit/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-04-08:16:18:25,270 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_world_religions from None to 5\n",
      "2024-04-08:16:18:25,272 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_moral_disputes from None to 5\n",
      "2024-04-08:16:18:25,273 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_jurisprudence from None to 5\n",
      "2024-04-08:16:18:25,273 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5\n",
      "2024-04-08:16:18:25,274 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5\n",
      "2024-04-08:16:18:25,275 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_philosophy from None to 5\n",
      "2024-04-08:16:18:25,275 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_professional_law from None to 5\n",
      "2024-04-08:16:18:25,276 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_prehistory from None to 5\n",
      "2024-04-08:16:18:25,276 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5\n",
      "2024-04-08:16:18:25,277 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5\n",
      "2024-04-08:16:18:25,278 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_formal_logic from None to 5\n",
      "2024-04-08:16:18:25,278 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_international_law from None to 5\n",
      "2024-04-08:16:18:25,279 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5\n",
      "2024-04-08:16:18:25,280 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5\n",
      "2024-04-08:16:18:25,280 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_human_sexuality from None to 5\n",
      "2024-04-08:16:18:25,281 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_security_studies from None to 5\n",
      "2024-04-08:16:18:25,281 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_sociology from None to 5\n",
      "2024-04-08:16:18:25,281 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5\n",
      "2024-04-08:16:18:25,282 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_geography from None to 5\n",
      "2024-04-08:16:18:25,282 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_econometrics from None to 5\n",
      "2024-04-08:16:18:25,282 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5\n",
      "2024-04-08:16:18:25,283 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5\n",
      "2024-04-08:16:18:25,283 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_public_relations from None to 5\n",
      "2024-04-08:16:18:25,283 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_professional_psychology from None to 5\n",
      "2024-04-08:16:18:25,284 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5\n",
      "2024-04-08:16:18:25,284 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_nutrition from None to 5\n",
      "2024-04-08:16:18:25,285 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_management from None to 5\n",
      "2024-04-08:16:18:25,285 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_business_ethics from None to 5\n",
      "2024-04-08:16:18:25,285 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_miscellaneous from None to 5\n",
      "2024-04-08:16:18:25,286 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_virology from None to 5\n",
      "2024-04-08:16:18:25,286 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_marketing from None to 5\n",
      "2024-04-08:16:18:25,286 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5\n",
      "2024-04-08:16:18:25,287 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_human_aging from None to 5\n",
      "2024-04-08:16:18:25,287 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_professional_accounting from None to 5\n",
      "2024-04-08:16:18:25,287 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_medicine from None to 5\n",
      "2024-04-08:16:18:25,288 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_medical_genetics from None to 5\n",
      "2024-04-08:16:18:25,288 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_global_facts from None to 5\n",
      "2024-04-08:16:18:25,288 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_professional_medicine from None to 5\n",
      "2024-04-08:16:18:25,289 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5\n",
      "2024-04-08:16:18:25,289 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_astronomy from None to 5\n",
      "2024-04-08:16:18:25,289 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5\n",
      "2024-04-08:16:18:25,290 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5\n",
      "2024-04-08:16:18:25,290 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_chemistry from None to 5\n",
      "2024-04-08:16:18:25,291 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5\n",
      "2024-04-08:16:18:25,291 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_biology from None to 5\n",
      "2024-04-08:16:18:25,291 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_anatomy from None to 5\n",
      "2024-04-08:16:18:25,292 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_physics from None to 5\n",
      "2024-04-08:16:18:25,292 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_physics from None to 5\n",
      "2024-04-08:16:18:25,292 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5\n",
      "2024-04-08:16:18:25,293 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5\n",
      "2024-04-08:16:18:25,293 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_computer_security from None to 5\n",
      "2024-04-08:16:18:25,294 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_machine_learning from None to 5\n",
      "2024-04-08:16:18:25,294 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5\n",
      "2024-04-08:16:18:25,295 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5\n",
      "2024-04-08:16:18:25,295 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_biology from None to 5\n",
      "2024-04-08:16:18:25,295 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_mathematics from None to 5\n",
      "2024-04-08:16:18:25,296 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_computer_science from None to 5\n",
      "2024-04-08:16:18:25,304 INFO     [task.py:395] Building contexts for mmlu_world_religions on rank 0...\n",
      "100%|██████████| 171/171 [00:02<00:00, 63.42it/s]\n",
      "2024-04-08:16:18:28,016 INFO     [task.py:395] Building contexts for mmlu_moral_disputes on rank 0...\n",
      "100%|██████████| 346/346 [00:05<00:00, 66.10it/s]\n",
      "2024-04-08:16:18:33,270 INFO     [task.py:395] Building contexts for mmlu_jurisprudence on rank 0...\n",
      "100%|██████████| 108/108 [00:01<00:00, 62.79it/s]\n",
      "2024-04-08:16:18:34,999 INFO     [task.py:395] Building contexts for mmlu_high_school_us_history on rank 0...\n",
      "100%|██████████| 204/204 [00:03<00:00, 65.73it/s]\n",
      "2024-04-08:16:18:38,117 INFO     [task.py:395] Building contexts for mmlu_high_school_world_history on rank 0...\n",
      "100%|██████████| 237/237 [00:03<00:00, 65.64it/s]\n",
      "2024-04-08:16:18:41,743 INFO     [task.py:395] Building contexts for mmlu_philosophy on rank 0...\n",
      "100%|██████████| 311/311 [00:04<00:00, 65.10it/s]\n",
      "2024-04-08:16:18:46,539 INFO     [task.py:395] Building contexts for mmlu_professional_law on rank 0...\n",
      "100%|██████████| 1534/1534 [00:24<00:00, 63.02it/s]\n",
      "2024-04-08:16:19:10,968 INFO     [task.py:395] Building contexts for mmlu_prehistory on rank 0...\n",
      "100%|██████████| 324/324 [00:05<00:00, 63.13it/s]\n",
      "2024-04-08:16:19:16,137 INFO     [task.py:395] Building contexts for mmlu_moral_scenarios on rank 0...\n",
      "100%|██████████| 895/895 [00:13<00:00, 66.74it/s]\n",
      "2024-04-08:16:19:29,593 INFO     [task.py:395] Building contexts for mmlu_high_school_european_history on rank 0...\n",
      "100%|██████████| 165/165 [00:02<00:00, 66.70it/s]\n",
      "2024-04-08:16:19:32,080 INFO     [task.py:395] Building contexts for mmlu_formal_logic on rank 0...\n",
      "100%|██████████| 126/126 [00:01<00:00, 67.38it/s]\n",
      "2024-04-08:16:19:33,959 INFO     [task.py:395] Building contexts for mmlu_international_law on rank 0...\n",
      "100%|██████████| 121/121 [00:01<00:00, 66.49it/s]\n",
      "2024-04-08:16:19:35,787 INFO     [task.py:395] Building contexts for mmlu_logical_fallacies on rank 0...\n",
      "100%|██████████| 163/163 [00:02<00:00, 67.62it/s]\n",
      "2024-04-08:16:19:38,208 INFO     [task.py:395] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.46it/s]\n",
      "2024-04-08:16:19:39,676 INFO     [task.py:395] Building contexts for mmlu_human_sexuality on rank 0...\n",
      "100%|██████████| 131/131 [00:01<00:00, 66.89it/s]\n",
      "2024-04-08:16:19:41,643 INFO     [task.py:395] Building contexts for mmlu_security_studies on rank 0...\n",
      "100%|██████████| 245/245 [00:03<00:00, 67.65it/s]\n",
      "2024-04-08:16:19:45,279 INFO     [task.py:395] Building contexts for mmlu_sociology on rank 0...\n",
      "100%|██████████| 201/201 [00:03<00:00, 66.72it/s]\n",
      "2024-04-08:16:19:48,307 INFO     [task.py:395] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
      "100%|██████████| 238/238 [00:03<00:00, 63.02it/s]\n",
      "2024-04-08:16:19:52,098 INFO     [task.py:395] Building contexts for mmlu_high_school_geography on rank 0...\n",
      "100%|██████████| 198/198 [00:03<00:00, 64.44it/s]\n",
      "2024-04-08:16:19:55,184 INFO     [task.py:395] Building contexts for mmlu_econometrics on rank 0...\n",
      "100%|██████████| 114/114 [00:01<00:00, 68.39it/s]\n",
      "2024-04-08:16:19:56,859 INFO     [task.py:395] Building contexts for mmlu_high_school_psychology on rank 0...\n",
      "100%|██████████| 545/545 [00:08<00:00, 63.80it/s]\n",
      "2024-04-08:16:20:05,429 INFO     [task.py:395] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
      "100%|██████████| 390/390 [00:06<00:00, 63.46it/s]\n",
      "2024-04-08:16:20:11,597 INFO     [task.py:395] Building contexts for mmlu_public_relations on rank 0...\n",
      "100%|██████████| 110/110 [00:02<00:00, 50.71it/s]\n",
      "2024-04-08:16:20:13,780 INFO     [task.py:395] Building contexts for mmlu_professional_psychology on rank 0...\n",
      "100%|██████████| 612/612 [00:09<00:00, 66.90it/s]\n",
      "2024-04-08:16:20:22,971 INFO     [task.py:395] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
      "100%|██████████| 193/193 [00:02<00:00, 68.91it/s]\n",
      "2024-04-08:16:20:25,785 INFO     [task.py:395] Building contexts for mmlu_nutrition on rank 0...\n",
      "100%|██████████| 306/306 [00:04<00:00, 67.66it/s]\n",
      "2024-04-08:16:20:30,324 INFO     [task.py:395] Building contexts for mmlu_management on rank 0...\n",
      "100%|██████████| 103/103 [00:01<00:00, 67.24it/s]\n",
      "2024-04-08:16:20:31,864 INFO     [task.py:395] Building contexts for mmlu_business_ethics on rank 0...\n",
      "100%|██████████| 100/100 [00:01<00:00, 67.98it/s]\n",
      "2024-04-08:16:20:33,344 INFO     [task.py:395] Building contexts for mmlu_miscellaneous on rank 0...\n",
      "100%|██████████| 783/783 [00:11<00:00, 65.79it/s]\n",
      "2024-04-08:16:20:45,289 INFO     [task.py:395] Building contexts for mmlu_virology on rank 0...\n",
      "100%|██████████| 166/166 [00:02<00:00, 64.73it/s]\n",
      "2024-04-08:16:20:47,866 INFO     [task.py:395] Building contexts for mmlu_marketing on rank 0...\n",
      "100%|██████████| 234/234 [00:03<00:00, 62.64it/s]\n",
      "2024-04-08:16:20:51,616 INFO     [task.py:395] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
      "100%|██████████| 265/265 [00:03<00:00, 66.35it/s]\n",
      "2024-04-08:16:20:55,625 INFO     [task.py:395] Building contexts for mmlu_human_aging on rank 0...\n",
      "100%|██████████| 223/223 [00:03<00:00, 68.53it/s]\n",
      "2024-04-08:16:20:58,893 INFO     [task.py:395] Building contexts for mmlu_professional_accounting on rank 0...\n",
      "100%|██████████| 282/282 [00:04<00:00, 68.62it/s]\n",
      "2024-04-08:16:21:03,020 INFO     [task.py:395] Building contexts for mmlu_college_medicine on rank 0...\n",
      "100%|██████████| 173/173 [00:02<00:00, 68.55it/s]\n",
      "2024-04-08:16:21:05,557 INFO     [task.py:395] Building contexts for mmlu_medical_genetics on rank 0...\n",
      "100%|██████████| 100/100 [00:01<00:00, 65.64it/s]\n",
      "2024-04-08:16:21:07,088 INFO     [task.py:395] Building contexts for mmlu_global_facts on rank 0...\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.47it/s]\n",
      "2024-04-08:16:21:08,557 INFO     [task.py:395] Building contexts for mmlu_professional_medicine on rank 0...\n",
      "100%|██████████| 272/272 [00:03<00:00, 68.44it/s]\n",
      "2024-04-08:16:21:12,550 INFO     [task.py:395] Building contexts for mmlu_electrical_engineering on rank 0...\n",
      "100%|██████████| 145/145 [00:02<00:00, 68.11it/s]\n",
      "2024-04-08:16:21:14,689 INFO     [task.py:395] Building contexts for mmlu_astronomy on rank 0...\n",
      "100%|██████████| 152/152 [00:02<00:00, 68.76it/s]\n",
      "2024-04-08:16:21:16,912 INFO     [task.py:395] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.25it/s]\n",
      "2024-04-08:16:21:18,385 INFO     [task.py:395] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
      "100%|██████████| 203/203 [00:02<00:00, 68.12it/s]\n",
      "2024-04-08:16:21:21,378 INFO     [task.py:395] Building contexts for mmlu_college_chemistry on rank 0...\n",
      "100%|██████████| 100/100 [00:01<00:00, 67.58it/s]\n",
      "2024-04-08:16:21:22,865 INFO     [task.py:395] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
      "100%|██████████| 270/270 [00:04<00:00, 66.03it/s]\n",
      "2024-04-08:16:21:26,970 INFO     [task.py:395] Building contexts for mmlu_college_biology on rank 0...\n",
      "100%|██████████| 144/144 [00:02<00:00, 67.22it/s]\n",
      "2024-04-08:16:21:29,123 INFO     [task.py:395] Building contexts for mmlu_anatomy on rank 0...\n",
      "100%|██████████| 135/135 [00:01<00:00, 69.30it/s]\n",
      "2024-04-08:16:21:31,079 INFO     [task.py:395] Building contexts for mmlu_college_physics on rank 0...\n",
      "100%|██████████| 102/102 [00:01<00:00, 68.48it/s]\n",
      "2024-04-08:16:21:32,576 INFO     [task.py:395] Building contexts for mmlu_high_school_physics on rank 0...\n",
      "100%|██████████| 151/151 [00:02<00:00, 67.54it/s]\n",
      "2024-04-08:16:21:34,822 INFO     [task.py:395] Building contexts for mmlu_high_school_statistics on rank 0...\n",
      "100%|██████████| 216/216 [00:03<00:00, 68.28it/s]\n",
      "2024-04-08:16:21:37,999 INFO     [task.py:395] Building contexts for mmlu_conceptual_physics on rank 0...\n",
      "100%|██████████| 235/235 [00:03<00:00, 64.50it/s]\n",
      "2024-04-08:16:21:41,656 INFO     [task.py:395] Building contexts for mmlu_computer_security on rank 0...\n",
      "100%|██████████| 100/100 [00:01<00:00, 67.98it/s]\n",
      "2024-04-08:16:21:43,135 INFO     [task.py:395] Building contexts for mmlu_machine_learning on rank 0...\n",
      "100%|██████████| 112/112 [00:01<00:00, 68.04it/s]\n",
      "2024-04-08:16:21:44,789 INFO     [task.py:395] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
      "100%|██████████| 378/378 [00:05<00:00, 66.86it/s]\n",
      "2024-04-08:16:21:50,463 INFO     [task.py:395] Building contexts for mmlu_abstract_algebra on rank 0...\n",
      "100%|██████████| 100/100 [00:01<00:00, 66.58it/s]\n",
      "2024-04-08:16:21:51,973 INFO     [task.py:395] Building contexts for mmlu_high_school_biology on rank 0...\n",
      "100%|██████████| 310/310 [00:04<00:00, 64.79it/s]\n",
      "2024-04-08:16:21:56,775 INFO     [task.py:395] Building contexts for mmlu_college_mathematics on rank 0...\n",
      "100%|██████████| 100/100 [00:01<00:00, 69.68it/s]\n",
      "2024-04-08:16:21:58,220 INFO     [task.py:395] Building contexts for mmlu_college_computer_science on rank 0...\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.56it/s]\n",
      "2024-04-08:16:21:59,685 INFO     [evaluator.py:379] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 56168/56168 [36:42<00:00, 25.50it/s] \n"
     ]
    }
   ],
   "source": [
    "# correct\n",
    "\n",
    "results = lm_eval.simple_evaluate(\n",
    "    model=\"hf\",\n",
    "    model_args=f\"pretrained={llama2},tokenizer={llama2}\",\n",
    "    tasks=['mmlu'],\n",
    "    num_fewshot=5,\n",
    "    task_manager=task_manager,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_dict2file(results['results'],\"mmlu_result.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10:12:23:54,377 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-04-10:12:23:54,379 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': '/mnt/sdb/zhanglongteng/data2/share/zhanglongteng_A6000/Llama-2-7b-hf', 'tokenizer': '/mnt/sdb/zhanglongteng/data2/share/zhanglongteng_A6000/Llama-2-7b-hf'}\n",
      "2024-04-10:12:23:54,386 INFO     [huggingface.py:163] Using device 'cuda'\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.30s/it]\n",
      "2024-04-10:12:24:12,094 WARNING  [evaluator.py:239] Overwriting default num_fewshot of gsm8k from 5 to 5\n",
      "2024-04-10:12:24:12,098 INFO     [task.py:395] Building contexts for gsm8k on rank 0...\n",
      "100%|██████████| 1319/1319 [00:08<00:00, 156.46it/s]\n",
      "2024-04-10:12:24:20,561 INFO     [evaluator.py:379] Running generate_until requests\n",
      "Running generate_until requests:   0%|          | 0/1319 [00:00<?, ?it/s]/mnt/sdb/zhanglongteng/anaconda3/envs/llmtoolkit/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/mnt/sdb/zhanglongteng/anaconda3/envs/llmtoolkit/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Running generate_until requests:   1%|▏         | 17/1319 [02:05<2:11:03,  6.04s/it]"
     ]
    }
   ],
   "source": [
    "gsm8k_results = lm_eval.simple_evaluate(\n",
    "    model=\"hf\",\n",
    "    model_args=f\"pretrained={llama2},tokenizer={llama2}\",\n",
    "    tasks=['gsm8k'],\n",
    "    num_fewshot=5,\n",
    "    task_manager=task_manager,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmtoolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
